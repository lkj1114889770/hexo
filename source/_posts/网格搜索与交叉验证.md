---
title: 网格搜索与Pipeline
date: 2017-11-23 20:03:19
tags:
	- 机器学习
---
学习机器学习有段时间了，第一参加了个比赛，京东JDD数据探索大赛，做了个[登陆识行为识别](http://jddjr.jd.com/item/1)。不得不说，在实际业务场景中用学的机器学习算法来解决问题，比想象中的难度还是大很多，毕竟实际问题其实比平时简单的算法应用复杂得多。虽然目前数据准确率还不是很高，这个数据集的正例和负例比例相差太大，而且数据上对于特征工程处理也有很大的难度。Anyway，毕竟是第一次参加这样的比赛，收获还是很大的，学到了很多新东西。比如网格搜索和Pipeline机制，以及一个神器Xgboost。先将网格搜索和交叉验证mark一下吧。
<!-- more -->

## 网格搜索
实际机器学习应用场景中的一个利器，通俗点就是暴力搜索。机器学习在应用的的时候，调参是一个很重要的环节，而网格搜索就在于优化参数搜索选择，更直白地说，就是你选择可能的参数集给你的分类器，然后网格搜索把这些可能的参数情况都运行一遍，按照你设定的score计算方式，返回score最高的参数。

函数原型：

	GridSearchCV(estimator, param_grid, scoring=None,
	   fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, 
	   verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’)

常用参数
**estimator**：所使用的分类器，如estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features='sqrt',random_state=10), 并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法。
**param_grid**：值为字典或者列表，即需要最优化的参数的取值，param_grid =param_test1，param_test1 = {'n_estimators':range(10,71,10)}。我用的Xgboost算法，优化的参数集为：

	parameters = {
	    'max_depth':[4,6],
	    'learning_rate':[0.1,0.3],
	    'subsample':[0.8,1.0],
	    'gamma':[0,3,5]
	}

**scoring** :准确度评价标准，默认None,这时需要使用score函数；或者如scoring='roc_auc'，根据所选模型不同，评价准则不同。字符串（函数名），或是可调用对象，需要其函数签名形如：scorer(estimator, X, y)；如果是None，则使用estimator的误差估计函数。scoring官方给的参数选择为[http://scikit-learn.org/stable/modules/model_evaluation.html](http://scikit-learn.org/stable/modules/model_evaluation.html)，当然也可以自定义，我在比赛中就按照JDD给的评分要求自定义了：

	from sklearn.metrics import fbeta_score,make_scorer
	#评估函数
	JdScore = make_scorer(fbeta_score,beta=0.1,greater_is_better=True)

**cv** :交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。
**verbose**：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，>1：对每个子模型都输出。
**n_jobs**: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值。

一个完整的网格搜索：

	from xgboost.sklearn import XGBClassifier
	#xgb的配置
	xgbFier = XGBClassifier(
    learning_rate =0.1,
    n_estimators=1000,
    max_depth=5,
    min_child_weight=1,
    gamma=0,
    subsample=0.8,
    colsample_bytree=0.8,
    objective= 'binary:logistic',
    scale_pos_weight=1,
    seed=27,
    silent=0
	)

	#网格搜索实验
	from sklearn.model_selection import GridSearchCV
	parameters = {
	    'max_depth':[4,6],
	    'learning_rate':[0.1,0.3],
	    'subsample':[0.8,1.0],
	    'gamma':[0,3,5]
	}
	gSearch  =GridSearchCV(xgbFier,parameters,n_jobs=-1,scoring=JdScore,cv=5)
	
	import time
	start =time.time()
	gSearch.fit(X_train,Y_train)
	runtime=time.time()-start
	print('run time:',runtime)
	print(gSearch.best_params_,gSearch.best_score_)

输出结果为：

	run time: 4109.730866909027
	{'gamma': 3, 'learning_rate': 0.1, 'max_depth': 6, 'subsample': 0.8} 0.738112481672

这样就找出了较优的参数，唉，现在只能得到0.78的线下score，还要继续修改啊。

## Pipeline机制
顾名思义就是管道机制，就是将机器学习整个流程流式化封装和管理，因为参数集在很多情况下对于测试集和训练集都是一样处理，他们有很多共同的步骤，这个机制就是便于这些步骤的共同使用。网上找到的一个很好解释的图如下，模型训练和预测过程中数据标准化、PCA降维之类的处理都可以通用，而且训练和预测用的是同一算法。

<center> <br>
<img width="500" height="400" src="http://img.blog.csdn.net/20160115095855517"> <br>
</center>

